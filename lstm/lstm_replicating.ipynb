{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torchinfo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z89ufoh_qny_",
        "outputId": "4e52990f-7fce-4a5c-9b73-310f14234e2a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
            "Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "zz9Qhl8RkjYy"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchinfo import summary"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from dataclasses import dataclass\n",
        "\n",
        "@dataclass\n",
        "class ModelArgs:\n",
        "  device = 'cpu'\n",
        "  input_size = 1\n",
        "  no_of_neurons = 128\n",
        "  block_size = 32\n",
        "  batch_size = 32\n",
        "  dropout = 0.1\n",
        "  epoch = 50\n",
        "  max_lr = 1e-4"
      ],
      "metadata": {
        "id": "I_dzPyF8liaB"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.set_default_device(ModelArgs.device)"
      ],
      "metadata": {
        "id": "1g217QFumAUE"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "torch.manual_seed(0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jH112V5lmO9k",
        "outputId": "aa2084df-e2d7-4ba2-b9b4-4a9c0ed88745"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x79ae19675710>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_samples = 1000\n",
        "seq_length = ModelArgs.block_size\n",
        "device = ModelArgs.device"
      ],
      "metadata": {
        "id": "MtHxZ18lqbCs"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t = torch.linspace(0, 100, num_samples + seq_length, device=device)"
      ],
      "metadata": {
        "id": "TBS0cmQuqgq6"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = t\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3msQatMzqu-c",
        "outputId": "0884f36e-b7e9-406a-d522-d65fcfec909b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.0000e+00, 9.6993e-02, 1.9399e-01,  ..., 9.9806e+01, 9.9903e+01,\n",
              "        1.0000e+02])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# normalize the data\n",
        "mean = data.mean()\n",
        "std = data.std()\n",
        "\n",
        "data = (data - mean) / std"
      ],
      "metadata": {
        "id": "PVC4ldW1OXew"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_tensor = torch.stack([data[i:i+seq_length] for i in range(num_samples)])\n",
        "X_tensor # each sequence + target value is 31 in length"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v9L9t4fiqw34",
        "outputId": "f52b32dc-99bb-4a6b-a131-af3b60501be1"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1.7295, -1.7262, -1.7228,  ..., -1.6322, -1.6289, -1.6255],\n",
              "        [-1.7262, -1.7228, -1.7195,  ..., -1.6289, -1.6255, -1.6222],\n",
              "        [-1.7228, -1.7195, -1.7161,  ..., -1.6255, -1.6222, -1.6188],\n",
              "        ...,\n",
              "        [ 1.6155,  1.6188,  1.6222,  ...,  1.7128,  1.7161,  1.7195],\n",
              "        [ 1.6188,  1.6222,  1.6255,  ...,  1.7161,  1.7195,  1.7228],\n",
              "        [ 1.6222,  1.6255,  1.6289,  ...,  1.7195,  1.7228,  1.7262]])"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# target value with index corresponding to the target values of X_tensor\n",
        "y_tensor = data[seq_length:]"
      ],
      "metadata": {
        "id": "7YhtmKN0HM-w"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1000 training sample inputs each a vector 32 in length\n",
        "X_tensor.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3DFcLrTMW7Z",
        "outputId": "cae20399-4477-463c-bbaa-49084e1406c3"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1000, 32])"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1000 training sample outputs each a target value\n",
        "y_tensor.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YD4-E-VUMVio",
        "outputId": "db0cd0ec-9214-4cba-8013-bc1b2ce34d88"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1000])"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = int(0.8 * num_samples)"
      ],
      "metadata": {
        "id": "0eialPHFMHVD"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Gp5IHBAMdwI",
        "outputId": "4a6f426f-dac3-428c-ae95-e661a48d7417"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "800"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, y_train = X_tensor[:train_size], y_tensor[:train_size]\n",
        "X_val, y_val = X_tensor[train_size:], y_tensor[train_size:]"
      ],
      "metadata": {
        "id": "yAeyWkiyMeRa"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This gets our original time series data and makes train and validation datasets.\n",
        "\n",
        "Each sample would look like this:\n",
        "```\n",
        "X = [4.91, 4.92, 4.93, ... , 5.10]\n",
        "y = 5.11\n",
        "```\n",
        "\n",
        "X is a sequence and y is the value right after that sequence.\n",
        "\n",
        "The goal of the model is to use the X sequence to predict what comes next (y)."
      ],
      "metadata": {
        "id": "w5EclYTlRW4j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TimeSeriesDataset(Dataset):\n",
        "  def __init__(self, X, y):\n",
        "    self.X = X\n",
        "    self.y = y\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.X)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.X[idx], self.y[idx]"
      ],
      "metadata": {
        "id": "heGrt2VkMj0g"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = TimeSeriesDataset(X_train, y_train)\n",
        "val_dataset = TimeSeriesDataset(X_val, y_val)"
      ],
      "metadata": {
        "id": "GAn1lq3jPo2b"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator = torch.Generator(device=device)"
      ],
      "metadata": {
        "id": "RBDziWHYPzkF"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=ModelArgs.batch_size,\n",
        "    shuffle=True,\n",
        "    generator=generator,\n",
        "    drop_last=True,\n",
        ")"
      ],
      "metadata": {
        "id": "9tr1v8UZP7fK"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=ModelArgs.batch_size,\n",
        "    shuffle=True,\n",
        "    generator=generator,\n",
        "    drop_last=True,\n",
        ")"
      ],
      "metadata": {
        "id": "6yrjQ3tcQIPr"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "BATCH = [\n",
        "  (X₁, y₁),\n",
        "  (X₂, y₂),\n",
        "  (X₃, y₃),\n",
        "  ...\n",
        "  (Xₙ, yₙ)\n",
        "]\n",
        "```\n",
        "\n",
        "Where `n = batch_size`\n",
        "\n",
        "Each sample is a tuple:\n",
        "\n",
        "```\n",
        "(sample) = (X, y)\n",
        "```\n",
        "\n",
        "And the sample shapes are\n",
        "\n",
        "```\n",
        "X = [ x₁, x₂, x₃, ... x_T ]   # T = seq_length\n",
        "y = x_(T+1)                   # next value\n",
        "```"
      ],
      "metadata": {
        "id": "D2xYvxLyRDIi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## States of LSTM\n",
        "\n",
        "- Cell State ($c_t$): Stores long term memory, updated at each step to carry information from entire previous time steps\n",
        "- Hidden State ($h_t$): Internal representation of the current time step, short-term memory\n",
        "- Input State ($x_t$): Input state at each time step, new information from the training data\n",
        "- Candidate Memory/Cell State ($g_t$ or $\\hat{c_t}$): New memory proposed cell state (long-term memory)\n",
        "\n"
      ],
      "metadata": {
        "id": "qKY5FpjgfSk-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The three gates of an LSTM model\n",
        "\n",
        "\n",
        "### The Forget Gate\n",
        "Decides which parts of the old memory are no longer useful. Decides the portion (as a percentage) of previous long-term memory are useful and should be written into the new cell state (long-term memory) at the current time step.\n",
        "\n",
        "$$\n",
        "f_t​ = \\sigma(U_f​x_t​ + V_f​h_{t−1​} + b_f)\n",
        "$$\n",
        "\n",
        "### Input Gate\n",
        "Decides what new information should be written into the long-term memory (cell-state) by creating a **candidate state** from the current input and previous hidden state, and using the input gate to control how much of that candidate is added to the cell state.\n",
        "\n",
        "Create candidate cell:\n",
        "$$\n",
        "g_t = \\hat{c_t} = \\tanh(U_cx_t + V_ch_{t-1} + b_c)\n",
        "$$\n",
        "\n",
        "Decide input of candidate cell:\n",
        "$$\n",
        "i_t = \\sigma(U_ix_t + V_ih_{t-1} + b_i)\n",
        "$$\n",
        "\n",
        "### Output Gate\n",
        "Decides how much of the internal long-term memory should influence the **current output**."
      ],
      "metadata": {
        "id": "MvVSZZbYR1Lm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ForgetGate(nn.Module):\n",
        "  def __init__(self, input_size: int, hidden_size: int):\n",
        "    super().__init__()\n",
        "    self.linear = nn.Linear(input_size + hidden_size, hidden_size)\n",
        "    nn.init.constant_(self.linear.bias, 1.0)\n",
        "\n",
        "  def forward(self, x_t, h_prev):\n",
        "    \"\"\"\n",
        "    x_t: (B, input_size)\n",
        "    h_prev: (B, hidden_size)\n",
        "\n",
        "    returns:\n",
        "    f_t: (B, hidden_size) values in range [0, 1]\n",
        "    \"\"\"\n",
        "    # combine current input and previous hidden state\n",
        "    z = torch.cat([x_t, h_prev], dim=1)\n",
        "    # apply W_f * z + b_f where W_f = [ U_f V_f ]\n",
        "    scores = self.linear(z)\n",
        "    # use sigmoid function to squash to [0,1] so each value is a keep percentage of the prev hidden state\n",
        "    f_t = torch.sigmoid(scores)\n",
        "    return f_t"
      ],
      "metadata": {
        "id": "XjsPq_aSyMOf"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class InputGate(nn.Module):\n",
        "  def __init__(self, input_size: int, hidden_size: int):\n",
        "    super().__init__()\n",
        "    # write strength (input gate) of candidate cell\n",
        "    self.linear_i = nn.Linear(input_size + hidden_size, hidden_size)\n",
        "\n",
        "    # candidate cell state (g_t)\n",
        "    self.linear_g = nn.Linear(input_size + hidden_size, hidden_size)\n",
        "\n",
        "  def forward(self, x_t, h_prev):\n",
        "    \"\"\"\n",
        "    x_t:    (B, input_size)\n",
        "    h_prev: (B, hidden_size)\n",
        "\n",
        "    returns:\n",
        "    i_t: (B, hidden_size)  values in [0,1]\n",
        "    g_t: (B, hidden_size)  values in [-1,1]\n",
        "    \"\"\"\n",
        "    z = torch.cat([x_t, h_prev], dim=1)\n",
        "\n",
        "    # calculate input gate\n",
        "    i_t = torch.sigmoid(self.linear_i(z))\n",
        "\n",
        "    # calculate candidate memory state\n",
        "    g_t = torch.tanh(self.linear_g(z))\n",
        "\n",
        "    return i_t, g_t"
      ],
      "metadata": {
        "id": "A6VL5x5nQMKM"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class OutputGate(nn.Module):\n",
        "  def __init__(self, input_size: int, hidden_size: int):\n",
        "    super().__init__()\n",
        "    self.linear = nn.Linear(input_size + hidden_size, hidden_size)\n",
        "\n",
        "  def forward(self, x_t, h_prev, c_t):\n",
        "    \"\"\"\n",
        "    x_t:    (B, input_size)\n",
        "    h_prev: (B, hidden_size)\n",
        "    c_t:    (B, hidden_size)\n",
        "\n",
        "    returns:\n",
        "    h_t:    (B, hidden_size)\n",
        "    \"\"\"\n",
        "    z = torch.cat([x_t, h_prev], dim=1)\n",
        "\n",
        "    # get output gate from the new input and hidden state\n",
        "    o_t = torch.sigmoid(self.linear(z))\n",
        "\n",
        "    # use output gate to calculate new hidden state\n",
        "    h_t = o_t * torch.tanh(c_t)\n",
        "\n",
        "    return h_t"
      ],
      "metadata": {
        "id": "C7Kp1Eb6R0Uk"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build the LSTM Block\n",
        "\n",
        "Now that we have all three gates constructed we can create a block of the model itself by combining each gate.\n",
        "\n",
        "See [video](https://www.youtube.com/watch?v=P_TZN8kRObQ) for good visual and explanation."
      ],
      "metadata": {
        "id": "WaOY_9IrpVfk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMBlock(nn.Module):\n",
        "  def __init__(self, input_size: int , hidden_size: int):\n",
        "    super().__init__()\n",
        "    self.forget_gate = ForgetGate(input_size, hidden_size)\n",
        "    self.input_gate = InputGate(input_size, hidden_size)\n",
        "    self.output_gate = OutputGate(input_size, hidden_size)\n",
        "\n",
        "  def forward(self, x_t, h_prev, c_prev):\n",
        "    # calculate forget gate (portion of previous cell state to carry forward)\n",
        "    f_t = self.forget_gate(x_t, h_prev)\n",
        "\n",
        "    # calcuate input gate and candidate cell\n",
        "    i_t, g_t = self.input_gate(x_t, h_prev)\n",
        "\n",
        "    # add gated previous cell state to gated candidate cell state to get the new cell state (long-term memory)\n",
        "    c_t = f_t * c_prev + i_t * g_t\n",
        "\n",
        "    # calculate new hidden state from output gate\n",
        "    h_t = self.output_gate(x_t, h_prev, c_t)\n",
        "\n",
        "    # return new hidden (short-term memory) and cell state (long-term memory) states\n",
        "    return h_t, c_t"
      ],
      "metadata": {
        "id": "Lf-OGZo7TZYI"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build the LSTM Model\n",
        "\n",
        "Use a bunch of blocks to train on our time series data and predict the next time step value."
      ],
      "metadata": {
        "id": "FJMQHjg1uwuj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTM(nn.Module):\n",
        "  def __init__(self, input_size: int, hidden_size: int):\n",
        "    super().__init__()\n",
        "\n",
        "    self.input_size = input_size\n",
        "    self.hidden_size = hidden_size\n",
        "    self.block = LSTMBlock(input_size, hidden_size)\n",
        "\n",
        "    # classifier head to project hidden size -> a prediction\n",
        "    self.output_layer = nn.Linear(hidden_size, 1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    \"\"\"\n",
        "    x: (B, T)  where T = seq_length\n",
        "\n",
        "    returns:\n",
        "    y_hat: (B, 1)\n",
        "    \"\"\"\n",
        "\n",
        "    B, T = x.shape\n",
        "\n",
        "    # initialize hidden and cell (long-term memory) states\n",
        "    h_t = torch.zeros(B, self.hidden_size, device=x.device)\n",
        "    c_t = torch.zeros(B, self.hidden_size, device=x.device)\n",
        "\n",
        "    # loop over each time step\n",
        "    for t in range(T):\n",
        "      x_t = x[:, t].unsqueeze(1) # (B,) -> (B, 1) because theres one input feature per output\n",
        "      h_t, c_t = self.block(x_t, h_t, c_t) # update the hidden and cell states from this time step's info\n",
        "\n",
        "    # make a prediction for the next time step using the classifier head\n",
        "    y_hat = self.output_layer(h_t)\n",
        "\n",
        "    return y_hat"
      ],
      "metadata": {
        "id": "757NozpidfZP"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training and validation\n",
        "\n",
        "Train on train mode using Adam optimizer and a learning rate scheduler `OneCycleLR`. Make sure to unnormalize the data to get the final prediction for each sample in each batch."
      ],
      "metadata": {
        "id": "DEgmE08TPMvx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = LSTM(\n",
        "    input_size = ModelArgs.input_size,\n",
        "    hidden_size = ModelArgs.no_of_neurons,\n",
        ")\n",
        "model.train()\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=ModelArgs.max_lr)\n",
        "scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
        "    optimizer,\n",
        "    max_lr=ModelArgs.max_lr,\n",
        "    steps_per_epoch=len(train_loader),\n",
        "    epochs=ModelArgs.epoch,\n",
        ")\n",
        "\n",
        "for epoch in range(ModelArgs.epoch):\n",
        "  model.train()\n",
        "  total_loss = 0.0\n",
        "\n",
        "  for X_batch, y_batch in train_loader:\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # fwd pass\n",
        "    y_hat = model(X_batch) # (B, 1)\n",
        "    y_hat = y_hat * std + mean # unnormalize\n",
        "    y_pred = y_hat.squeeze(1) # (B,)\n",
        "\n",
        "    # compute loss\n",
        "    loss = criterion(y_pred, y_batch)\n",
        "\n",
        "    # backprop\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "\n",
        "    total_loss += loss.item()\n",
        "\n",
        "  avg_loss = total_loss / len(train_loader)\n",
        "  print(f\"Epoch {epoch+1}: train loss = {avg_loss:.6f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4KAJtMnFD5Ec",
        "outputId": "c3baee36-da19-4b14-d4f2-350e0ea05dff"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: train loss = 2397.902324\n",
            "Epoch 2: train loss = 2378.868936\n",
            "Epoch 3: train loss = 2349.022568\n",
            "Epoch 4: train loss = 2300.263096\n",
            "Epoch 5: train loss = 2222.255635\n",
            "Epoch 6: train loss = 2091.929160\n",
            "Epoch 7: train loss = 1813.954336\n",
            "Epoch 8: train loss = 939.904421\n",
            "Epoch 9: train loss = 34.085828\n",
            "Epoch 10: train loss = 2.403552\n",
            "Epoch 11: train loss = 0.697988\n",
            "Epoch 12: train loss = 0.401623\n",
            "Epoch 13: train loss = 0.284706\n",
            "Epoch 14: train loss = 0.221260\n",
            "Epoch 15: train loss = 0.189299\n",
            "Epoch 16: train loss = 0.168996\n",
            "Epoch 17: train loss = 0.157685\n",
            "Epoch 18: train loss = 0.150368\n",
            "Epoch 19: train loss = 0.145399\n",
            "Epoch 20: train loss = 0.139878\n",
            "Epoch 21: train loss = 0.136679\n",
            "Epoch 22: train loss = 0.132295\n",
            "Epoch 23: train loss = 0.128215\n",
            "Epoch 24: train loss = 0.124786\n",
            "Epoch 25: train loss = 0.121103\n",
            "Epoch 26: train loss = 0.118269\n",
            "Epoch 27: train loss = 0.115027\n",
            "Epoch 28: train loss = 0.112713\n",
            "Epoch 29: train loss = 0.109381\n",
            "Epoch 30: train loss = 0.106874\n",
            "Epoch 31: train loss = 0.104789\n",
            "Epoch 32: train loss = 0.102314\n",
            "Epoch 33: train loss = 0.100603\n",
            "Epoch 34: train loss = 0.098490\n",
            "Epoch 35: train loss = 0.097185\n",
            "Epoch 36: train loss = 0.095792\n",
            "Epoch 37: train loss = 0.094479\n",
            "Epoch 38: train loss = 0.093040\n",
            "Epoch 39: train loss = 0.092124\n",
            "Epoch 40: train loss = 0.091218\n",
            "Epoch 41: train loss = 0.090704\n",
            "Epoch 42: train loss = 0.090055\n",
            "Epoch 43: train loss = 0.089503\n",
            "Epoch 44: train loss = 0.089086\n",
            "Epoch 45: train loss = 0.088861\n",
            "Epoch 46: train loss = 0.088566\n",
            "Epoch 47: train loss = 0.088428\n",
            "Epoch 48: train loss = 0.088353\n",
            "Epoch 49: train loss = 0.088321\n",
            "Epoch 50: train loss = 0.088309\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Validation Loop\n",
        "\n",
        "Same thing as training except freeze all gradients so nothing can be updated during training. No back propagation."
      ],
      "metadata": {
        "id": "S-HtVvp2Pg07"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "  validation_loss = 0.0\n",
        "  for X_batch, y_batch in val_loader:\n",
        "    y_hat = model(X_batch).squeeze(1)\n",
        "    y_pred = y_hat * std + mean\n",
        "\n",
        "    loss = criterion(y_pred, y_batch)\n",
        "\n",
        "    validation_loss += loss.item()\n",
        "\n",
        "  validation_loss /= len(val_loader)\n",
        "  print(f\"Validation loss = {validation_loss:.6f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75sKw_u_E7Lq",
        "outputId": "420f6bed-0250-408f-8854-b12d0e01e66a"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss = 3.540914\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusion\n",
        "\n",
        "In general you should see the training and validation pretty low because the LSTM is rather overkill for predicitng a linear relationship made using `torch.linspace`."
      ],
      "metadata": {
        "id": "KJQyXCgKPLa_"
      }
    }
  ]
}